# -*- coding: utf-8 -*-

import io
import hashlib
import os
import sys
import re
import time
import shutil
import threading
import tempfile
import pandas as pd
import streamlit as st
from PIL import Image
from services.convert_service import DOCX2PDF_AVAILABLE
from services.preview_service import get_pdf_page_image
from services.reference_service import (
    safe_normalize_reference_text,
    split_reference_items,
    match_citations,
)
from services.analysis_service import run_file_analysis
from services.export_service import build_excel_report_bytes
from services.job_service import (
    JOB_STATUS_CANCELED,
    JOB_STATUS_DONE,
    JOB_STATUS_FAILED,
    JOB_STATUS_QUEUED,
    JOB_STATUS_RUNNING,
    cancel_job,
    get_job,
    get_latest_job_for_hash,
    submit_docx_to_pdf_job,
)
from utils.errors import AppError, ReferenceSectionNotFoundError

# Try to import PyMuPDF (fitz)
try:
    import fitz  # PyMuPDF, need `pip install pymupdf`
except ImportError:
    fitz = None

st.set_page_config(page_title="è«–æ–‡æ–‡ç»æ ¸å°å·¥å…·", layout="wide")

# ----------------------------------------------------------------
# è‡ªå®šç¾© CSS èˆ‡ JavaScript (å„ªåŒ–ä»‹é¢èˆ‡éš±è—ä¸å¿…è¦çš„å…ƒç´ )
# ----------------------------------------------------------------
st.markdown("""
<style>
    /* å¼·åˆ¶è®“ä¸Šå‚³å€å¡Šè®Šå¤§ä¸¦åŠ ä¸Šè™›ç·šé‚Šæ¡† */
    div[data-testid="stFileUploader"] section {
        padding: 60px 20px;
        background-color: #f8f9fa;
        border: 3px dashed #cccccc;
        border-radius: 15px;
        text-align: center;
        transition: all 0.2s ease-in-out;
    }

    /* åˆä½µ Drag & Hover æ¨£å¼ */
    .drag-active,
    div[data-testid="stFileUploader"] section:hover {
        background-color: #e8f5e9 !important;
        border-color: #4CAF50 !important;
        transform: scale(1.01) !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1) !important;
        cursor: pointer;
    }

    div[data-testid="stFileUploader"] section > div {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    }

    /* éš±è— "Browse files" æŒ‰éˆ• */
    div[data-testid="stFileUploader"] button {
        display: none !important;
    }
    
    div[data-testid="stFileUploader"] small {
        font-size: 0.9em;
        color: #666;
    }
    
    div[data-testid="stFileUploader"] section > * {
        pointer-events: none;
    }

    /* === ä»‹é¢ç²¾ç°¡å„ªåŒ– === */
    
    /* éš±è—å³ä¸Šè§’çš„ Deploy æŒ‰éˆ•èˆ‡é¸å–® */
    .stDeployButton, [data-testid="stToolbar"] {
        display: none !important;
    }
    
    /* éš±è—å´é‚Šæ¬„å±•é–‹æŒ‰éˆ• */
    [data-testid="collapsedControl"] {
        display: none !important;
    }
    
    /* éš±è— Footer */
    footer {
        display: none !important;
    }
    
    /* èª¿æ•´é ‚éƒ¨ Paddingï¼Œè®“å…§å®¹æ›´ç·Šæ¹Š */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 5rem; /* åº•éƒ¨ç•™ç™½ï¼Œé¿å…è¢«æµ®å‹•æŒ‰éˆ•æ“‹ä½ */
    }

    /* === ä¿®æ­£ï¼šçµæŸæŒ‰éˆ•ç¸®å°ã€åŠ ä¸Šå·¦å´æ–‡å­—ï¼Œä¸¦å›ºå®šåœ¨å³ä¸‹è§’ === */
</style>

<script>
(function() {
    function addDragListeners(element) {
        if (element.dataset.dragListener === "true") return;
        let dragCounter = 0;
        element.addEventListener('dragenter', (e) => {
            e.preventDefault();
            dragCounter++;
            element.classList.add('drag-active');
        });
        element.addEventListener('dragover', (e) => {
            e.preventDefault();
        });
        element.addEventListener('dragleave', (e) => {
            e.preventDefault();
            dragCounter--;
            if (dragCounter === 0) {
                element.classList.remove('drag-active');
            }
        });
        element.addEventListener('drop', (e) => {
            dragCounter = 0;
            element.classList.remove('drag-active');
        });
        element.dataset.dragListener = "true";
    }

    const observer = new MutationObserver(() => {
        const uploaderSection = document.querySelector('div[data-testid="stFileUploader"] section');
        if (uploaderSection) {
            addDragListeners(uploaderSection);
        }
    });

    observer.observe(document.body, { childList: true, subtree: true });
})();
</script>
""", unsafe_allow_html=True)

# ----------------------------------------------------------------
# å›ºå®šåœ¨å³ä¸‹è§’çš„çµæŸç¨‹å¼æŒ‰éˆ•
# ----------------------------------------------------------------

# ----------------------------------------------------------------
# Helper: DOCX è½‰ PDF
# ----------------------------------------------------------------
# ----------------------------------------------------------------
# Helper: PDF è¦–è¦ºåŒ– (åš´è¬¹ç‰ˆï¼šé¿å…éåº¦åé»ƒ)
# ----------------------------------------------------------------
# ----------------------------------------------------------------
# ä¸»ç¨‹å¼
# ----------------------------------------------------------------
st.title("è«–æ–‡æ–‡ç»æ ¸å°å·¥å…·")
st.warning("âš ï¸ **å…è²¬è²æ˜**ï¼šæœ¬å·¥å…·åƒ…ä¾›è¼”åŠ©åƒè€ƒï¼Œç„¡æ³•å–ä»£äººå·¥æ ¡å°ã€‚è§£æçµæœå¯èƒ½å› æª”æ¡ˆæ’ç‰ˆã€OCR å“è³ªæˆ–æ ¼å¼å·®ç•°è€Œæœ‰èª¤å·®ï¼Œè«‹å‹™å¿…è‡ªè¡Œç¢ºèªåŸå§‹æ–‡ä»¶ã€‚")

if fitz is None:
    st.error("éŒ¯èª¤ï¼šç¼ºå°‘ PDF è™•ç†å…ƒä»¶ (PyMuPDF)ï¼Œé è¦½åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ã€‚")

if "file_bytes" not in st.session_state:
    st.session_state.file_bytes = None
if "file_type" not in st.session_state:
    st.session_state.file_type = None
if "check_results" not in st.session_state:
    st.session_state.check_results = None
if "last_processed_key" not in st.session_state:
    st.session_state.last_processed_key = None
if "docx_pdf_job_id" not in st.session_state:
    st.session_state.docx_pdf_job_id = None
if "docx_pdf_job_key" not in st.session_state:
    st.session_state.docx_pdf_job_key = None
if "docx_pdf_file_hash" not in st.session_state:
    st.session_state.docx_pdf_file_hash = None
if "ref_tool_formatted_text" not in st.session_state:
    st.session_state.ref_tool_formatted_text = None
if "ref_tool_report" not in st.session_state:
    st.session_state.ref_tool_report = None
if "ref_tool_clean_text" not in st.session_state:
    st.session_state.ref_tool_clean_text = None
if "ref_tool_raw_output" not in st.session_state:
    st.session_state.ref_tool_raw_output = None
if "ref_tool_sorted_output" not in st.session_state:
    st.session_state.ref_tool_sorted_output = None

with st.expander("å·¥å…·1ï¼šæ–‡ç»åˆ—è¡¨æ•´ç†ï¼ˆSAFE onlyï¼‰", expanded=False):
    raw_ref_text = st.text_area(
        "è²¼ä¸ŠåŸå§‹æ–‡ç»åˆ—è¡¨ï¼ˆrawï¼‰",
        key="ref_tool_raw_text",
        height=180,
    )
    if st.button("åŸ·è¡Œ SAFE æ•´ç†", key="ref_tool_run"):
        clean_text = safe_normalize_reference_text(raw_ref_text)
        st.session_state.ref_tool_raw_output = raw_ref_text
        st.session_state.ref_tool_clean_text = clean_text
        st.session_state.ref_tool_formatted_text = clean_text

        raw_items = split_reference_items(raw_ref_text)
        clean_items = split_reference_items(clean_text)
        sorted_clean_items = sorted(clean_items, key=lambda item: item.lower())
        st.session_state.ref_tool_sorted_output = "\n\n".join(sorted_clean_items) if sorted_clean_items else clean_text
        st.session_state.ref_tool_report = {
            "raw_items": len(raw_items),
            "clean_items": len(clean_items),
        }

    if st.session_state.ref_tool_clean_text is not None:
        report = st.session_state.ref_tool_report or {}
        st.caption(
            f"SAFE normalize å®Œæˆï¼šraw_items={report.get('raw_items', 0)}, "
            f"clean_items={report.get('clean_items', 0)}ï¼ˆåªåšå­—å…ƒ/ç©ºç™½æ­£è¦åŒ–ï¼Œä¸åšæ¨æ¸¬åˆä½µæ‹†åˆ†ï¼‰"
        )
        st.text_area(
            "raw_text",
            value=st.session_state.ref_tool_raw_output or "",
            height=140,
        )
        st.text_area(
            "clean_textï¼ˆå·¥å…·2å°‡å„ªå…ˆä½¿ç”¨ï¼‰",
            value=st.session_state.ref_tool_clean_text or "",
            height=220,
        )
        st.text_area(
            "A-Z æ’åºé¡¯ç¤º/è¼¸å‡ºï¼ˆåƒ…æ”¹é †åºï¼Œä¸æ”¹å…§å®¹ï¼‰",
            value=st.session_state.ref_tool_sorted_output or "",
            height=220,
        )
        if st.session_state.ref_tool_sorted_output:
            st.download_button(
                "ä¸‹è¼‰ clean list (.txt)",
                data=st.session_state.ref_tool_sorted_output,
                file_name="references_safe_clean_sorted.txt",
                mime="text/plain",
                key="ref_tool_download_txt",
            )

uploaded = st.file_uploader("è«‹æ‹–æ›³æª”æ¡ˆè‡³æ­¤ (æ”¯æ´ PDF / Word)", type=["docx", "pdf"])

if not uploaded:
    st.info("""
    ğŸ’¡ **æ“ä½œæ­¥é©Ÿï¼š**
    1. å°‡ Word æˆ– PDF æª”æ‹–æ›³åˆ°ä¸Šæ–¹æ¡†æ¡†ã€‚
    2. ç­‰å¾…ç¨‹å¼è‡ªå‹•åˆ†æã€‚
    3. é»æ“Šä¸‹æ–¹è¡¨æ ¼æŸ¥çœ‹è©³ç´°çµæœã€‚
    """)

if uploaded:
    raw_bytes = uploaded.getvalue()
    raw_type = uploaded.name.split(".")[-1].lower()
    
    use_conversion = False
    
    status_container = st.container()
    metrics_container = st.container()
    st.markdown("---")
    col_left, col_right = st.columns([1.5, 1])

    with col_right:
        st.subheader("ğŸ“„ é è¦½è¦–çª—")
        if fitz is None:
            st.error("é è¦½åŠŸèƒ½å¤±æ•ˆ (ç¼º PyMuPDF)")
        elif raw_type == "docx":
            if DOCX2PDF_AVAILABLE:
                st.info("ğŸ’¡ ç›®å‰ç‚ºç´”æ–‡å­—æ ¸å°æ¨¡å¼ã€‚")
                use_conversion = st.checkbox("å•Ÿç”¨ Word è½‰ PDF è¦–è¦ºåŒ–é è¦½ (éœ€ç¨å€™å¹¾ç§’)", value=False)
                st.markdown("---")
            else:
                st.caption("ç›®å‰åƒ…æ”¯æ´ Word ç´”æ–‡å­—æ ¸å° (æœªåµæ¸¬åˆ°è½‰æª”å…ƒä»¶)ã€‚")
                st.markdown("---")

    content_hash = hashlib.sha256(raw_bytes).hexdigest()
    current_key = f"{uploaded.name}_{use_conversion}_{content_hash}"

    with status_container:
        conversion_pending = False

        if st.session_state.last_processed_key != current_key:
            st.session_state.filename = uploaded.name
            st.session_state.check_results = None
            st.session_state.last_processed_key = current_key

            if raw_type == "docx" and use_conversion:
                st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                st.session_state.docx_pdf_job_key = current_key
                st.session_state.docx_pdf_file_hash = content_hash
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
            else:
                st.session_state.docx_pdf_job_id = None
                st.session_state.docx_pdf_job_key = None
                st.session_state.docx_pdf_file_hash = None
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = raw_type

        if raw_type == "docx" and use_conversion:
            active_job_id = st.session_state.get("docx_pdf_job_id")
            if not active_job_id:
                latest = get_latest_job_for_hash(content_hash)
                if latest and latest.status in (JOB_STATUS_QUEUED, JOB_STATUS_RUNNING, JOB_STATUS_DONE):
                    active_job_id = latest.job_id
                    st.session_state.docx_pdf_job_id = active_job_id
                    st.session_state.docx_pdf_file_hash = content_hash

            job = get_job(active_job_id) if active_job_id else None

            if job is None:
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
                st.warning("Conversion job expired. Please resubmit.")
                if st.button("Resubmit conversion", key=f"retry_docx_pdf_{content_hash}"):
                    st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                    st.session_state.docx_pdf_job_key = current_key
                    st.session_state.docx_pdf_file_hash = content_hash
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
                    st.stop()
            elif job.status == JOB_STATUS_DONE and job.result_bytes:
                if st.session_state.file_type != "pdf":
                    st.session_state.check_results = None
                    st.success("Conversion succeeded. Preview mode enabled.")
                st.session_state.file_bytes = job.result_bytes
                st.session_state.file_type = "pdf"
            elif job.status == JOB_STATUS_FAILED:
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
                st.error("Conversion timed out or failed (Word not responding). Switched back to text mode.")
            elif job.status == JOB_STATUS_CANCELED:
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
                st.warning("Conversion canceled.")
                if st.button("Resubmit conversion", key=f"retry_canceled_docx_pdf_{content_hash}"):
                    st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                    st.session_state.docx_pdf_job_key = current_key
                    st.session_state.docx_pdf_file_hash = content_hash
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
                    st.stop()
            elif job.status == JOB_STATUS_QUEUED:
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
                st.info("Word conversion queued...")
                if st.button("Cancel conversion", key=f"cancel_docx_pdf_{active_job_id}"):
                    cancel_job(active_job_id)
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
                    st.stop()
                conversion_pending = True
            elif job.status == JOB_STATUS_RUNNING:
                st.session_state.file_bytes = raw_bytes
                st.session_state.file_type = "docx"
                st.info("Word conversion running...")
                if st.button("Cancel conversion", key=f"cancel_docx_pdf_{active_job_id}"):
                    cancel_job(active_job_id)
                    try:
                        st.rerun()
                    except Exception:
                        try:
                            st.experimental_rerun()
                        except Exception:
                            pass
                    st.stop()
                conversion_pending = True

        file_bytes = st.session_state.file_bytes
        file_type = st.session_state.file_type

        if conversion_pending:
            time.sleep(0.3)
            try:
                st.rerun()
            except Exception:
                try:
                    st.experimental_rerun()
                except Exception:
                    pass
            st.stop()

        if st.session_state.check_results is None:
            try:
                with st.spinner("Analyzing citations..."):
                    results = run_file_analysis(
                        file_bytes=file_bytes,
                        filename=st.session_state.filename,
                        file_type=file_type,
                    )
                    st.session_state.check_results = results
            except ReferenceSectionNotFoundError as e:
                st.error(f"{e.message}")
                st.stop()
            except AppError as e:
                st.error(f"{e.message}")
                st.stop()
            except Exception as e:
                st.error(f"Analysis error: {e}")
                st.stop()

    summary_df, matched_df, missing_df, uncited_df = st.session_state.check_results

    safe_linked_match_result = None
    safe_clean_text = st.session_state.get("ref_tool_clean_text") or ""
    if safe_clean_text.strip():
        citation_raw_parts = []
        for frame in (matched_df, missing_df):
            if isinstance(frame, pd.DataFrame) and "citation_raw" in frame.columns:
                for value in frame["citation_raw"].tolist():
                    value_text = str(value).strip()
                    if value_text:
                        citation_raw_parts.append(value_text)

        if citation_raw_parts:
            try:
                clean_reference_items = split_reference_items(safe_clean_text)
                safe_linked_match_result = match_citations(
                    text="\n".join(citation_raw_parts),
                    reference_items=clean_reference_items,
                )
            except Exception:
                safe_linked_match_result = None

    with metrics_container:
        col_m1, col_m2, col_m3 = st.columns(3)
        col_m1.metric("æˆåŠŸé…å°", len(matched_df))
        col_m2.metric("éºæ¼å¼•ç”¨ (éœ€è£œ)", len(missing_df), delta_color="inverse")
        col_m3.metric("æœªè¢«å¼•ç”¨ (éœ€åˆª)", len(uncited_df), delta_color="inverse")
        if safe_linked_match_result is not None:
            st.caption("å·²ä½¿ç”¨å·¥å…·1çš„ clean_textï¼ˆSAFE normalizeï¼‰åš citation key æ¯”å°ã€‚")
            st.caption(
                f"key matched={len(safe_linked_match_result.get('matched', []))}, "
                f"missing_in_reference={len(safe_linked_match_result.get('missing_in_reference', []))}, "
                f"extra_in_reference={len(safe_linked_match_result.get('extra_in_reference', []))}"
            )
            with st.expander("SAFE key æ¯”å°æ˜ç´°", expanded=False):
                st.write("matched:", safe_linked_match_result.get("matched", []))
                st.write("missing_in_reference:", safe_linked_match_result.get("missing_in_reference", []))
                st.write("extra_in_reference:", safe_linked_match_result.get("extra_in_reference", []))

    preview_img = None
    preview_caption = "ğŸ‘ˆ é»æ“Šå·¦å´è¡¨æ ¼è¡Œå¯é è¦½å…§å®¹"

    with col_left:
        tab1, tab2, tab3 = st.tabs([
            f"âŒ éºæ¼å¼•ç”¨ ({len(missing_df)})",
            f"âš ï¸ æœªè¢«å¼•ç”¨ ({len(uncited_df)})",
            f"âœ… æˆåŠŸé…å° ({len(matched_df)})",
        ])

        grid_height = 400
        select_mode = "single-row"
        
        def show_table(df, key_suffix):
            event = st.dataframe(
                df, 
                use_container_width=True, 
                height=grid_height,
                on_select="rerun", 
                selection_mode=select_mode,
                hide_index=True,
                key=f"df_{key_suffix}"
            )
            return event

        with tab1:
            st.caption("æ­£æ–‡æœ‰å¼•ç”¨ï¼Œä½†åƒè€ƒæ–‡ç»åˆ—è¡¨æ‰¾ä¸åˆ°ã€‚")
            if not missing_df.empty:
                evt = show_table(missing_df, "missing")
                if evt.selection.rows:
                    row = missing_df.iloc[evt.selection.rows[0]]
                    if file_type == "pdf":
                        page_num = row.get("page", 1)
                        preview_caption = f"éºæ¼å¼•ç”¨ - Page {page_num}"
                        preview_img = get_pdf_page_image(file_bytes, page_num, row.get("citation_raw", ""))
            else:
                st.success("å¤ªæ£’äº†ï¼æ²’æœ‰ç™¼ç¾éºæ¼çš„å¼•ç”¨ã€‚")

        with tab2:
            st.caption("å‡ºç¾åœ¨æ–‡ç»åˆ—è¡¨ï¼Œä½†æ­£æ–‡æœªå¼•ç”¨ã€‚")
            if not uncited_df.empty:
                evt = show_table(uncited_df, "uncited")
                if evt.selection.rows:
                    row = uncited_df.iloc[evt.selection.rows[0]]
                    if file_type == "pdf":
                        page_num = row.get("page", 1)
                        preview_caption = f"æœªè¢«å¼•ç”¨ - Page {page_num}"
                        preview_img = get_pdf_page_image(file_bytes, page_num, row.get("åƒè€ƒæ–‡ç»åŸæ–‡", ""))
            else:
                st.success("å®Œç¾ï¼æ‰€æœ‰åƒè€ƒæ–‡ç»éƒ½æœ‰è¢«ä½¿ç”¨ã€‚")

        with tab3:
            st.caption("é…å°æˆåŠŸçš„é …ç›®ã€‚")
            if not matched_df.empty:
                evt = show_table(matched_df, "matched")
                if evt.selection.rows:
                    row = matched_df.iloc[evt.selection.rows[0]]
                    view_mode = st.radio("é è¦½ä½ç½®", ["æ­£æ–‡å¼•ç”¨", "åƒè€ƒæ–‡ç»"], horizontal=True, label_visibility="collapsed")
                    
                    if file_type == "pdf":
                        if view_mode == "æ­£æ–‡å¼•ç”¨":
                            page_num = row.get("page", 1)
                            hl = row.get("citation_raw", "")
                            preview_caption = f"æ­£æ–‡ - Page {page_num}"
                        else:
                            page_num = row.get("ref_page", 1)
                            hl = row.get("ref_raw", "")
                            preview_caption = f"æ–‡ç»åˆ—è¡¨ - Page {page_num}"
                        preview_img = get_pdf_page_image(file_bytes, page_num, hl)
            else:
                st.info("å°šæœªæœ‰é…å°çµæœã€‚")

    with col_right:
        if fitz is not None:
            if file_type == "docx":
                st.warning("âš ï¸ Word ç´”æ–‡å­—æ¨¡å¼ä¸æ”¯æ´åœ–ç‰‡é è¦½ã€‚è«‹å‹¾é¸ä¸Šæ–¹é¸é …å•Ÿç”¨ã€‚")
                st.info("""
                ğŸ’¡ **é—œæ–¼è½‰æª”æ¨¡å¼çš„å–æ¨ï¼š**
                * **å„ªé» (Pros)**ï¼šå¯å•Ÿç”¨è¦–è¦ºåŒ–é è¦½ï¼Œç¨‹å¼æœƒç”¨ç´…æ¡†è‡ªå‹•æ¨™ç¤ºå‡ºå¼•ç”¨çš„ä½ç½®ï¼Œäººå·¥æ ¸å°æ›´ç›´è¦ºã€‚
                * **ç¼ºé» (Cons)**ï¼šéœ€ç­‰å¾…è½‰æª”æ™‚é–“ï¼Œä¸” PDF çš„è§£æç²¾æº–åº¦é€šå¸¸ç•¥ä½æ–¼ Word ç´”æ–‡å­—æ¨¡å¼ï¼ˆæ–‡å­—å¯èƒ½å› æ’ç‰ˆè€Œç ´ç¢æˆ–èª¤åˆ¤ï¼‰ã€‚
                """)
            else:
                st.info(preview_caption)
                if preview_img:
                    st.image(preview_img, use_container_width=True)
                elif file_type == "pdf" and "é»æ“Š" in preview_caption:
                    st.write("ç­‰å¾…é¸å–...")
                else:
                    st.write("...")

    st.markdown("---")

    st.download_button(
        "ğŸ“¥ ä¸‹è¼‰ Excel å®Œæ•´å ±å‘Š",
        build_excel_report_bytes(summary_df, matched_df, missing_df, uncited_df),
        "citation_report.xlsx",
        type="primary"
    )
