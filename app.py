# -*- coding: utf-8 -*-

import io
import hashlib
import os
import sys
import re
import time
import shutil
import threading
import tempfile
import streamlit as st
from PIL import Image
from services.convert_service import DOCX2PDF_AVAILABLE
from services.preview_service import get_pdf_page_image
from services.reference_service import (
    safe_normalize_reference_text,
    split_reference_items,
)
from services.analysis_service import (
    ANALYSIS_ENGINE_VERSION,
    run_file_analysis_with_reference_override,
)
from services.export_service import build_excel_report_bytes
from utils.chinese_sort import load_stroke_map, chinese_stroke_sort_key
from services.job_service import (
    JOB_STATUS_CANCELED,
    JOB_STATUS_DONE,
    JOB_STATUS_FAILED,
    JOB_STATUS_QUEUED,
    JOB_STATUS_RUNNING,
    cancel_job,
    get_job,
    get_latest_job_for_hash,
    submit_docx_to_pdf_job,
)
from utils.errors import AppError, ReferenceSectionNotFoundError


def _contains_cjk_unified_char(text: str) -> bool:
    return any(0x4E00 <= ord(ch) <= 0x9FFF for ch in (text or ""))


def _tool1_reference_sort_key(item: str, stroke_map: dict[str, int]) -> tuple:
    text = (item or "").strip()
    if not text:
        return (3, "")
    # å·¥å…·1æ’åºï¼šä¸­æ–‡åœ¨å‰ã€è‹±æ–‡åœ¨å¾Œã€‚
    if _contains_cjk_unified_char(text):
        strokes, key_char, raw_text = chinese_stroke_sort_key(text, stroke_map)
        return (0, strokes, key_char, raw_text.lower())
    if re.match(r"^[A-Za-z]", text):
        return (1, text.lower())
    return (2, text.lower())

# Try to import PyMuPDF (fitz)
try:
    import fitz  # PyMuPDF, need `pip install pymupdf`
except ImportError:
    fitz = None

st.set_page_config(page_title="è«–æ–‡æ–‡ç»æ ¸å°å·¥å…·", layout="wide")

# ----------------------------------------------------------------
# è‡ªå®šç¾© CSS èˆ‡ JavaScript (å„ªåŒ–ä»‹é¢èˆ‡éš±è—ä¸å¿…è¦çš„å…ƒç´ )
# ----------------------------------------------------------------
st.markdown("""
<style>
    /* å¼·åˆ¶è®“ä¸Šå‚³å€å¡Šè®Šå¤§ä¸¦åŠ ä¸Šè™›ç·šé‚Šæ¡† */
    div[data-testid="stFileUploader"] section {
        padding: 60px 20px;
        background-color: #f8f9fa;
        border: 3px dashed #cccccc;
        border-radius: 15px;
        text-align: center;
        transition: all 0.2s ease-in-out;
    }

    /* åˆä½µ Drag & Hover æ¨£å¼ */
    .drag-active,
    div[data-testid="stFileUploader"] section:hover {
        background-color: #e8f5e9 !important;
        border-color: #4CAF50 !important;
        transform: scale(1.01) !important;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1) !important;
        cursor: pointer;
    }

    div[data-testid="stFileUploader"] section > div {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
    }

    /* éš±è— "Browse files" æŒ‰éˆ• */
    div[data-testid="stFileUploader"] button {
        display: none !important;
    }
    
    div[data-testid="stFileUploader"] small {
        font-size: 0.9em;
        color: #666;
    }
    
    div[data-testid="stFileUploader"] section > * {
        pointer-events: none;
    }

    /* === ä»‹é¢ç²¾ç°¡å„ªåŒ– === */
    
    /* éš±è—å³ä¸Šè§’çš„ Deploy æŒ‰éˆ•èˆ‡é¸å–® */
    .stDeployButton, [data-testid="stToolbar"] {
        display: none !important;
    }
    
    /* éš±è—å´é‚Šæ¬„å±•é–‹æŒ‰éˆ• */
    [data-testid="collapsedControl"] {
        display: none !important;
    }
    
    /* éš±è— Footer */
    footer {
        display: none !important;
    }
    
    /* èª¿æ•´é ‚éƒ¨ Paddingï¼Œè®“å…§å®¹æ›´ç·Šæ¹Š */
    .block-container {
        padding-top: 2rem;
        padding-bottom: 5rem; /* åº•éƒ¨ç•™ç™½ï¼Œé¿å…è¢«æµ®å‹•æŒ‰éˆ•æ“‹ä½ */
    }

    /* === ä¿®æ­£ï¼šçµæŸæŒ‰éˆ•ç¸®å°ã€åŠ ä¸Šå·¦å´æ–‡å­—ï¼Œä¸¦å›ºå®šåœ¨å³ä¸‹è§’ === */
</style>

<script>
(function() {
    function addDragListeners(element) {
        if (element.dataset.dragListener === "true") return;
        let dragCounter = 0;
        element.addEventListener('dragenter', (e) => {
            e.preventDefault();
            dragCounter++;
            element.classList.add('drag-active');
        });
        element.addEventListener('dragover', (e) => {
            e.preventDefault();
        });
        element.addEventListener('dragleave', (e) => {
            e.preventDefault();
            dragCounter--;
            if (dragCounter === 0) {
                element.classList.remove('drag-active');
            }
        });
        element.addEventListener('drop', (e) => {
            dragCounter = 0;
            element.classList.remove('drag-active');
        });
        element.dataset.dragListener = "true";
    }

    const observer = new MutationObserver(() => {
        const uploaderSection = document.querySelector('div[data-testid="stFileUploader"] section');
        if (uploaderSection) {
            addDragListeners(uploaderSection);
        }
    });

    observer.observe(document.body, { childList: true, subtree: true });
})();
</script>
""", unsafe_allow_html=True)

# ----------------------------------------------------------------
# å›ºå®šåœ¨å³ä¸‹è§’çš„çµæŸç¨‹å¼æŒ‰éˆ•
# ----------------------------------------------------------------

# ----------------------------------------------------------------
# Helper: DOCX è½‰ PDF
# ----------------------------------------------------------------
# ----------------------------------------------------------------
# Helper: PDF è¦–è¦ºåŒ– (åš´è¬¹ç‰ˆï¼šé¿å…éåº¦åé»ƒ)
# ----------------------------------------------------------------
# ----------------------------------------------------------------
# ä¸»ç¨‹å¼
# ----------------------------------------------------------------
st.title("è«–æ–‡æ–‡ç»æ ¸å°å·¥å…·")
st.warning("âš ï¸ **å…è²¬è²æ˜**ï¼šæœ¬å·¥å…·åƒ…ä¾›è¼”åŠ©åƒè€ƒï¼Œç„¡æ³•å–ä»£äººå·¥æ ¡å°ã€‚è§£æçµæœå¯èƒ½å› æª”æ¡ˆæ’ç‰ˆã€OCR å“è³ªæˆ–æ ¼å¼å·®ç•°è€Œæœ‰èª¤å·®ï¼Œè«‹å‹™å¿…è‡ªè¡Œç¢ºèªåŸå§‹æ–‡ä»¶ã€‚")

if fitz is None:
    st.error("éŒ¯èª¤ï¼šç¼ºå°‘ PDF è™•ç†å…ƒä»¶ (PyMuPDF)ï¼Œé è¦½åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨ã€‚")

if "file_bytes" not in st.session_state:
    st.session_state.file_bytes = None
if "file_type" not in st.session_state:
    st.session_state.file_type = None
if "check_results" not in st.session_state:
    st.session_state.check_results = None
if "analysis_meta" not in st.session_state:
    st.session_state.analysis_meta = None
if "last_processed_key" not in st.session_state:
    st.session_state.last_processed_key = None
if "docx_pdf_job_id" not in st.session_state:
    st.session_state.docx_pdf_job_id = None
if "docx_pdf_job_key" not in st.session_state:
    st.session_state.docx_pdf_job_key = None
if "docx_pdf_file_hash" not in st.session_state:
    st.session_state.docx_pdf_file_hash = None
if "ref_tool_formatted_text" not in st.session_state:
    st.session_state.ref_tool_formatted_text = None
if "ref_tool_report" not in st.session_state:
    st.session_state.ref_tool_report = None
if "ref_tool_clean_text" not in st.session_state:
    st.session_state.ref_tool_clean_text = None
if "ref_tool_raw_output" not in st.session_state:
    st.session_state.ref_tool_raw_output = None
if "ref_tool_sorted_output" not in st.session_state:
    st.session_state.ref_tool_sorted_output = None
if "use_clean_references_for_analysis" not in st.session_state:
    st.session_state.use_clean_references_for_analysis = True
if "reference_source_mode_ui" not in st.session_state:
    st.session_state.reference_source_mode_ui = "ä½¿ç”¨å·¥å…·1æ•´ç†å¾Œæ–‡ç»åˆ—è¡¨æé«˜æº–ç¢ºåº¦"

tool_page_tool1, tool_page_tool2 = st.tabs(["æ–‡ç»åˆ—è¡¨æ’åˆ—", "æ–‡ç»å°æ¯”"])

with tool_page_tool1:
    raw_ref_text = st.text_area(
        "è²¼ä¸Šæ–‡ç»åˆ—è¡¨",
        key="ref_tool_raw_text",
        height=180,
    )
    if st.button("åŸ·è¡Œæ•´ç†", key="ref_tool_run"):
        clean_text = safe_normalize_reference_text(raw_ref_text)
        raw_items = split_reference_items(raw_ref_text)
        clean_items = split_reference_items(clean_text)
        try:
            stroke_map = load_stroke_map()
        except Exception:
            stroke_map = {}
        sorted_clean_items = sorted(clean_items, key=lambda item: _tool1_reference_sort_key(item, stroke_map))
        final_clean_text = "\n".join(sorted_clean_items) if sorted_clean_items else clean_text.strip()

        st.session_state.ref_tool_raw_output = raw_ref_text
        st.session_state.ref_tool_clean_text = final_clean_text
        st.session_state.ref_tool_formatted_text = final_clean_text
        st.session_state.ref_tool_sorted_output = final_clean_text
        st.session_state.ref_tool_report = {
            "raw_items": len(raw_items),
            "clean_items": len(clean_items),
        }

    if st.session_state.ref_tool_clean_text is not None:
        report = st.session_state.ref_tool_report or {}
        st.caption(
            f"æ•´ç†å®Œæˆï¼šåŸå§‹ç­†æ•¸={report.get('raw_items', 0)}, "
            f"æ•´ç†å¾Œç­†æ•¸={report.get('clean_items', 0)}"
        )
        st.text_area(
            "çµæœ",
            value=st.session_state.ref_tool_clean_text or "",
            height=260,
        )
        if st.session_state.ref_tool_clean_text:
            st.download_button(
                "ä¸‹è¼‰çµæœ(.txt)",
                data=st.session_state.ref_tool_clean_text,
                file_name="references_safe_clean_sorted.txt",
                mime="text/plain",
                key="ref_tool_download_txt",
            )
    else:
        st.info("å°šæœªç”¢ç”Ÿæ•´ç†çµæœã€‚è«‹è²¼ä¸Šæ–‡ç»åˆ—è¡¨å¾ŒåŸ·è¡Œ æ•´ç†ã€‚")


with tool_page_tool2:
    uploaded = st.file_uploader("è«‹æ‹–æ›³æª”æ¡ˆè‡³æ­¤ (æ”¯æ´ PDF / Word)", type=["docx", "pdf"])
    clean_reference_text = (st.session_state.get("ref_tool_clean_text") or "").strip()
    option_tool1 = "ä½¿ç”¨å·¥å…·1æ•´ç†å¾Œæ–‡ç»åˆ—è¡¨æé«˜æº–ç¢ºåº¦"
    option_auto = "ä½¿ç”¨æ–‡ä»¶è‡ªå‹•æŠ½å–çš„æ–‡ç»åˆ—è¡¨"

    auto_switched_to_auto = (
        uploaded is not None
        and st.session_state.get("reference_source_mode_ui") == option_tool1
        and not clean_reference_text
    )
    if auto_switched_to_auto:
        st.session_state.reference_source_mode_ui = option_auto
        st.session_state.use_clean_references_for_analysis = False

    reference_source_mode = st.radio(
        "æ–‡ç»ä¾†æº",
        options=[option_tool1, option_auto],
        horizontal=True,
        key="reference_source_mode_ui",
    )
    st.session_state.use_clean_references_for_analysis = reference_source_mode == option_tool1
    if auto_switched_to_auto:
        st.info("åµæ¸¬åˆ°å·¥å…·1å°šç„¡å¯ç”¨æ•´ç†çµæœï¼Œå·²è‡ªå‹•åˆ‡æ›ç‚ºã€Œä½¿ç”¨æ–‡ä»¶è‡ªå‹•æŠ½å–çš„æ–‡ç»åˆ—è¡¨ã€ã€‚")

    if not uploaded:
        st.info("""
        ğŸ’¡ **æ“ä½œæ­¥é©Ÿï¼š**
        1. å°‡ Word æˆ– PDF æª”æ‹–æ›³åˆ°ä¸Šæ–¹æ¡†æ¡†ã€‚
        2. ç­‰å¾…ç¨‹å¼è‡ªå‹•åˆ†æã€‚
        3. é»æ“Šä¸‹æ–¹è¡¨æ ¼æŸ¥çœ‹è©³ç´°çµæœã€‚
        """)

    if uploaded:
        raw_bytes = uploaded.getvalue()
        raw_type = uploaded.name.split(".")[-1].lower()
        
        use_conversion = False
        
        status_container = st.container()
        metrics_container = st.container()
        st.markdown("---")
        col_left, col_right = st.columns([1.5, 1])

        with col_right:
            st.subheader("ğŸ“„ é è¦½è¦–çª—")
            if fitz is None:
                st.error("é è¦½åŠŸèƒ½å¤±æ•ˆ (ç¼º PyMuPDF)")
            elif raw_type == "docx":
                if DOCX2PDF_AVAILABLE:
                    st.info("ğŸ’¡ ç›®å‰ç‚ºç´”æ–‡å­—æ ¸å°æ¨¡å¼ã€‚")
                    use_conversion = st.checkbox("å•Ÿç”¨ Word è½‰ PDF è¦–è¦ºåŒ–é è¦½ (éœ€ç¨å€™å¹¾ç§’)", value=False)
                    st.markdown("---")
                else:
                    st.caption("ç›®å‰åƒ…æ”¯æ´ Word ç´”æ–‡å­—æ ¸å° (æœªåµæ¸¬åˆ°è½‰æª”å…ƒä»¶)ã€‚")
                    st.markdown("---")

        use_reference_override = st.session_state.get("use_clean_references_for_analysis", True)
        if use_reference_override and not clean_reference_text:
            st.info("ç›®å‰å°šç„¡å·¥å…·1æ•´ç†çµæœï¼Œæœ¬æ¬¡å°‡æ”¹ç”¨æ–‡ä»¶è‡ªå‹•æŠ½å–çš„æ–‡ç»åˆ—è¡¨ã€‚")
            use_reference_override = False

        override_reference_text = clean_reference_text if (clean_reference_text and use_reference_override) else None
        override_signature = (
            hashlib.sha256(override_reference_text.encode("utf-8")).hexdigest()
            if override_reference_text
            else "auto"
        )

        content_hash = hashlib.sha256(raw_bytes).hexdigest()
        current_key = f"{uploaded.name}_{use_conversion}_{content_hash}_{override_signature}_{ANALYSIS_ENGINE_VERSION}"

        with status_container:
            conversion_pending = False

            if st.session_state.last_processed_key != current_key:
                st.session_state.filename = uploaded.name
                st.session_state.check_results = None
                st.session_state.analysis_meta = None
                st.session_state.last_processed_key = current_key

                if raw_type == "docx" and use_conversion:
                    st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                    st.session_state.docx_pdf_job_key = current_key
                    st.session_state.docx_pdf_file_hash = content_hash
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                else:
                    st.session_state.docx_pdf_job_id = None
                    st.session_state.docx_pdf_job_key = None
                    st.session_state.docx_pdf_file_hash = None
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = raw_type

            if raw_type == "docx" and use_conversion:
                active_job_id = st.session_state.get("docx_pdf_job_id")
                if not active_job_id:
                    latest = get_latest_job_for_hash(content_hash)
                    if latest and latest.status in (JOB_STATUS_QUEUED, JOB_STATUS_RUNNING, JOB_STATUS_DONE):
                        active_job_id = latest.job_id
                        st.session_state.docx_pdf_job_id = active_job_id
                        st.session_state.docx_pdf_file_hash = content_hash

                job = get_job(active_job_id) if active_job_id else None

                if job is None:
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                    st.warning("Conversion job expired. Please resubmit.")
                    if st.button("Resubmit conversion", key=f"retry_docx_pdf_{content_hash}"):
                        st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                        st.session_state.docx_pdf_job_key = current_key
                        st.session_state.docx_pdf_file_hash = content_hash
                        try:
                            st.rerun()
                        except Exception:
                            try:
                                st.experimental_rerun()
                            except Exception:
                                pass
                        st.stop()
                elif job.status == JOB_STATUS_DONE and job.result_bytes:
                    if st.session_state.file_type != "pdf":
                        st.session_state.check_results = None
                        st.success("Conversion succeeded. Preview mode enabled.")
                    st.session_state.file_bytes = job.result_bytes
                    st.session_state.file_type = "pdf"
                elif job.status == JOB_STATUS_FAILED:
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                    st.error("Conversion timed out or failed (Word not responding). Switched back to text mode.")
                elif job.status == JOB_STATUS_CANCELED:
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                    st.warning("Conversion canceled.")
                    if st.button("Resubmit conversion", key=f"retry_canceled_docx_pdf_{content_hash}"):
                        st.session_state.docx_pdf_job_id = submit_docx_to_pdf_job(raw_bytes)
                        st.session_state.docx_pdf_job_key = current_key
                        st.session_state.docx_pdf_file_hash = content_hash
                        try:
                            st.rerun()
                        except Exception:
                            try:
                                st.experimental_rerun()
                            except Exception:
                                pass
                        st.stop()
                elif job.status == JOB_STATUS_QUEUED:
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                    st.info("Word conversion queued...")
                    if st.button("Cancel conversion", key=f"cancel_docx_pdf_{active_job_id}"):
                        cancel_job(active_job_id)
                        try:
                            st.rerun()
                        except Exception:
                            try:
                                st.experimental_rerun()
                            except Exception:
                                pass
                        st.stop()
                    conversion_pending = True
                elif job.status == JOB_STATUS_RUNNING:
                    st.session_state.file_bytes = raw_bytes
                    st.session_state.file_type = "docx"
                    st.info("Word conversion running...")
                    if st.button("Cancel conversion", key=f"cancel_docx_pdf_{active_job_id}"):
                        cancel_job(active_job_id)
                        try:
                            st.rerun()
                        except Exception:
                            try:
                                st.experimental_rerun()
                            except Exception:
                                pass
                        st.stop()
                    conversion_pending = True

            file_bytes = st.session_state.file_bytes
            file_type = st.session_state.file_type

            if conversion_pending:
                time.sleep(0.3)
                try:
                    st.rerun()
                except Exception:
                    try:
                        st.experimental_rerun()
                    except Exception:
                        pass
                st.stop()

            if st.session_state.check_results is None:
                try:
                    with st.spinner("Analyzing citations..."):
                        results, analysis_meta = run_file_analysis_with_reference_override(
                            file_bytes=file_bytes,
                            filename=st.session_state.filename,
                            file_type=file_type,
                            override_reference_text=override_reference_text,
                        )
                        st.session_state.check_results = results
                        st.session_state.analysis_meta = analysis_meta
                except ReferenceSectionNotFoundError as e:
                    st.error(f"{e.message}")
                    st.stop()
                except AppError as e:
                    st.error(f"{e.message}")
                    st.stop()
                except Exception as e:
                    st.error(f"Analysis error: {e}")
                    st.stop()

        summary_df, matched_df, missing_df, uncited_df = st.session_state.check_results
        analysis_meta = st.session_state.get("analysis_meta") or {}

        with metrics_container:
            col_m1, col_m2, col_m3 = st.columns(3)
            col_m1.metric("Matched", len(matched_df))
            col_m2.metric("Missing In-Text", len(missing_df), delta_color="inverse")
            col_m3.metric("Uncited References", len(uncited_df), delta_color="inverse")

            reference_source = analysis_meta.get("reference_source", "auto_extracted")
            reference_count = analysis_meta.get("reference_item_count", 0)
            if reference_source == "user_override":
                st.caption(f"æ–‡ç»ä¾†æºï¼šä½¿ç”¨å·¥å…·1æ•´ç†å¾Œæ–‡ç»åˆ—è¡¨ï¼ˆç­†æ•¸={reference_count}ï¼‰")
            else:
                st.caption(f"æ–‡ç»ä¾†æºï¼šæ–‡ä»¶è‡ªå‹•æŠ½å–æ–‡ç»åˆ—è¡¨ï¼ˆç­†æ•¸={reference_count}ï¼‰")

            warning_text = (analysis_meta.get("warning") or "").strip()
            if warning_text:
                st.warning(warning_text)

        preview_img = None
        preview_caption = "ğŸ‘ˆ é»æ“Šå·¦å´è¡¨æ ¼è¡Œå¯é è¦½å…§å®¹"

        with col_left:
            tab1, tab2, tab3 = st.tabs([
                f"âŒ éºæ¼å¼•ç”¨ ({len(missing_df)})",
                f"âš ï¸ æœªè¢«å¼•ç”¨ ({len(uncited_df)})",
                f"âœ… æˆåŠŸé…å° ({len(matched_df)})",
            ])

            grid_height = 400
            select_mode = "single-row"
            
            def show_table(df, key_suffix):
                event = st.dataframe(
                    df, 
                    use_container_width=True, 
                    height=grid_height,
                    on_select="rerun", 
                    selection_mode=select_mode,
                    hide_index=True,
                    key=f"df_{key_suffix}"
                )
                return event

            with tab1:
                st.caption("æ­£æ–‡æœ‰å¼•ç”¨ï¼Œä½†åƒè€ƒæ–‡ç»åˆ—è¡¨æ‰¾ä¸åˆ°ã€‚")
                if not missing_df.empty:
                    evt = show_table(missing_df, "missing")
                    if evt.selection.rows:
                        row = missing_df.iloc[evt.selection.rows[0]]
                        if file_type == "pdf":
                            page_num = row.get("page", 1)
                            preview_caption = f"éºæ¼å¼•ç”¨ - Page {page_num}"
                            preview_img = get_pdf_page_image(file_bytes, page_num, row.get("citation_raw", ""))
                else:
                    st.success("å¤ªæ£’äº†ï¼æ²’æœ‰ç™¼ç¾éºæ¼çš„å¼•ç”¨ã€‚")

            with tab2:
                st.caption("å‡ºç¾åœ¨æ–‡ç»åˆ—è¡¨ï¼Œä½†æ­£æ–‡æœªå¼•ç”¨ã€‚")
                if not uncited_df.empty:
                    evt = show_table(uncited_df, "uncited")
                    if evt.selection.rows:
                        row = uncited_df.iloc[evt.selection.rows[0]]
                        if file_type == "pdf":
                            page_num = row.get("page", 1)
                            preview_caption = f"æœªè¢«å¼•ç”¨ - Page {page_num}"
                            preview_img = get_pdf_page_image(file_bytes, page_num, row.get("åƒè€ƒæ–‡ç»åŸæ–‡", ""))
                else:
                    st.success("å®Œç¾ï¼æ‰€æœ‰åƒè€ƒæ–‡ç»éƒ½æœ‰è¢«ä½¿ç”¨ã€‚")

            with tab3:
                st.caption("é…å°æˆåŠŸçš„é …ç›®ã€‚")
                if not matched_df.empty:
                    evt = show_table(matched_df, "matched")
                    if evt.selection.rows:
                        row = matched_df.iloc[evt.selection.rows[0]]
                        view_mode = st.radio("é è¦½ä½ç½®", ["æ­£æ–‡å¼•ç”¨", "åƒè€ƒæ–‡ç»"], horizontal=True, label_visibility="collapsed")
                        
                        if file_type == "pdf":
                            if view_mode == "æ­£æ–‡å¼•ç”¨":
                                page_num = row.get("page", 1)
                                hl = row.get("citation_raw", "")
                                preview_caption = f"æ­£æ–‡ - Page {page_num}"
                            else:
                                page_num = row.get("ref_page", 1)
                                hl = row.get("ref_raw", "")
                                preview_caption = f"æ–‡ç»åˆ—è¡¨ - Page {page_num}"
                            preview_img = get_pdf_page_image(file_bytes, page_num, hl)
                else:
                    st.info("å°šæœªæœ‰é…å°çµæœã€‚")

        with col_right:
            if fitz is not None:
                if file_type == "docx":
                    st.warning("âš ï¸ Word ç´”æ–‡å­—æ¨¡å¼ä¸æ”¯æ´åœ–ç‰‡é è¦½ã€‚è«‹å‹¾é¸ä¸Šæ–¹é¸é …å•Ÿç”¨ã€‚")
                    st.info("""
                    ğŸ’¡ **é—œæ–¼è½‰æª”æ¨¡å¼çš„å–æ¨ï¼š**
                    * **å„ªé» (Pros)**ï¼šå¯å•Ÿç”¨è¦–è¦ºåŒ–é è¦½ï¼Œç¨‹å¼æœƒç”¨ç´…æ¡†è‡ªå‹•æ¨™ç¤ºå‡ºå¼•ç”¨çš„ä½ç½®ï¼Œäººå·¥æ ¸å°æ›´ç›´è¦ºã€‚
                    * **ç¼ºé» (Cons)**ï¼šéœ€ç­‰å¾…è½‰æª”æ™‚é–“ï¼Œä¸” PDF çš„è§£æç²¾æº–åº¦é€šå¸¸ç•¥ä½æ–¼ Word ç´”æ–‡å­—æ¨¡å¼ï¼ˆæ–‡å­—å¯èƒ½å› æ’ç‰ˆè€Œç ´ç¢æˆ–èª¤åˆ¤ï¼‰ã€‚
                    """)
                else:
                    st.info(preview_caption)
                    if preview_img:
                        st.image(preview_img, use_container_width=True)
                    elif file_type == "pdf" and "é»æ“Š" in preview_caption:
                        st.write("ç­‰å¾…é¸å–...")
                    else:
                        st.write("...")

        st.markdown("---")

        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰ Excel å®Œæ•´å ±å‘Š",
            build_excel_report_bytes(summary_df, matched_df, missing_df, uncited_df),
            "citation_report.xlsx",
            type="primary"
        )
